# ML-Interpretability---Adversarial-Noise
Trick an image classification model into misclassifying an altered image as a specified target class, regardless of the original content
